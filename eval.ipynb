{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d68a81a-e3f3-454e-989e-bddf98d6c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "cache_dir = '/home/mila/s/soroush.omranpour/scratch/hf_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca5a4a7-1350-4bd1-8367-f820ad4c1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeClueDataset(Dataset):\n",
    "    def __init__(self, data_dir, processor, train=False):\n",
    "        super().__init__()\n",
    "        self.data_dir = os.path.join(data_dir, 'train' if train else 'test')\n",
    "        json_path = os.path.join(data_dir, f'data_json/{\"train\" if train else \"test\"}.json')\n",
    "        self.df = pd.read_json(json_path)\n",
    "        self.df = self.df[(self.df.cate != 'doc') & (self.df.cate != 'satellite')]\n",
    "        self.df.reset_index(inplace=True, drop=True)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.df.loc[idx, 'image'])\n",
    "        label = 1 - self.df.loc[idx, 'label'] ## in the dataset real=1 and fake=0\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        image = image.convert(\"RGB\")\n",
    "        inputs = self.processor(image, return_tensors=\"pt\")['pixel_values'][0]\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e7e03b-0831-4763-993d-3d14000c98e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2048208335cd433885a1cc7c0e70b323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import safetensors\n",
    "from transformers import AutoModelForImageClassification, AutoConfig\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# processor = AutoImageProcessor.from_pretrained(\n",
    "#     \"microsoft/swinv2-small-patch4-window16-256\", cache_dir=cache_dir, use_fast=True\n",
    "# )\n",
    "processor = AutoImageProcessor.from_pretrained(\n",
    "    \"facebook/convnextv2-base-22k-224\", cache_dir=cache_dir, use_fast=True\n",
    ")\n",
    "model = AutoModelForImageClassification.from_pretrained('weights/convnext').eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf889f85-a54f-4fe4-85b9-321cba8e5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549\n"
     ]
    }
   ],
   "source": [
    "dataset = FakeClueDataset(\n",
    "    data_dir=\"/home/mila/s/soroush.omranpour/scratch/FakeClue\", \n",
    "    processor=processor, \n",
    "    train=False\n",
    ")\n",
    "print(len(dataset))\n",
    "test_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=66,\n",
    "    shuffle=False,\n",
    "    num_workers=6,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f4ba5-29f7-4da2-a7e9-2688da539c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b24fbbea3c46cfbb5e7b8de84c4296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "gt = []\n",
    "pred = []\n",
    "with torch.inference_mode():\n",
    "    for x, y in tqdm(test_dataloader):    \n",
    "        pred += [model(x.to(device)).logits.argmax(-1).detach().cpu()]\n",
    "        gt += [y]\n",
    "    gt = torch.cat(gt)\n",
    "    pred = torch.cat(pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688cb029-fe66-4c2d-b513-221e426001f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5503    0.9937    0.7083      1260\n",
      "           1     0.9937    0.5531    0.7106      2289\n",
      "\n",
      "    accuracy                         0.7095      3549\n",
      "   macro avg     0.7720    0.7734    0.7095      3549\n",
      "weighted avg     0.8363    0.7095    0.7098      3549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt, pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "764b6fcd-d9bd-432a-a95c-71bd67276309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3192), tensor(1539))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.sum(), pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d62b55-b3a8-42ac-81fc-e0daab554385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
